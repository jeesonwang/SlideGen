from pathlib import Path

from loguru import logger

from slidegen.exception.custom_exception import FileParseError
from slidegen.schemas.file_upload import ParsedFileContent
from slidegen.schemas.gen_request import GeneratePresentationRequest
from slidegen.utils.file_manager import FileManager
from slidegen.workflows.docparse import DocumentReader
from slidegen.workflows.knowledge.kb_manager import KnowledgeBaseManager


class FileProcessor:
    """å¤„ç†ä¸Šä¼ æ–‡ä»¶çš„è§£æå’Œå†…å®¹æå–"""

    def __init__(self, file_manager: FileManager | None = None):
        """
        åˆå§‹åŒ–æ–‡ä»¶å¤„ç†å™¨

        Args:
            file_manager: æ–‡ä»¶ç®¡ç†å™¨å®ä¾‹,å¦‚æœä¸ºNoneåˆ™åˆ›å»ºæ–°å®ä¾‹
        """
        self.file_manager = file_manager or FileManager()
        self.markdown_converter = DocumentReader()
        logger.info("FileProcessor initialized")

    def parse_file(self, file_path: str) -> ParsedFileContent:
        """
        è§£æå•ä¸ªæ–‡ä»¶å¹¶è¿”å›Markdownå†…å®¹

        Args:
            file_path: æ–‡ä»¶è·¯å¾„

        Returns:
            ParsedFileContentå¯¹è±¡,åŒ…å«è§£æåçš„å†…å®¹

        Raises:
            FileParseError: æ–‡ä»¶è§£æå¤±è´¥
        """
        try:
            logger.info(f"Parsing file: {file_path}")

            # ä½¿ç”¨DocumentReaderè§£ææ–‡ä»¶
            result = self.markdown_converter.convert(file_path)

            # æå–æ–‡ä»¶åå’ŒID
            path = Path(file_path)
            filename = path.name

            # å°è¯•ä»æ–‡ä»¶åè§£æfile_id (æ ¼å¼: {file_id}_{original_filename})
            file_id = filename.split("_")[0] if "_" in filename else filename

            # ç»Ÿè®¡å­—æ•°
            word_count = len(result.text_content)

            parsed_content = ParsedFileContent(
                file_id=file_id,
                filename=filename,
                content=result.text_content,
                word_count=word_count,
            )

            logger.info(f"Successfully parsed {filename}: {word_count} words, {len(result.text_content)} characters")

            return parsed_content

        except Exception as e:
            logger.error(f"Failed to parse file {file_path}: {e}")
            raise FileParseError(f"æ— æ³•è§£ææ–‡ä»¶ {Path(file_path).name}: {str(e)}")

    def parse_files(self, file_paths: list[str]) -> str:
        """
        è§£æå¤šä¸ªæ–‡ä»¶å¹¶åˆå¹¶å†…å®¹

        Args:
            file_paths: æ–‡ä»¶è·¯å¾„åˆ—è¡¨

        Returns:
            åˆå¹¶åçš„Markdownå†…å®¹

        Raises:
            FileParseError: æ–‡ä»¶è§£æå¤±è´¥
        """
        if not file_paths:
            return ""

        merged_content = []
        parsed_count = 0

        for file_path in file_paths:
            try:
                parsed = self.parse_file(file_path)

                # æ·»åŠ æ–‡ä»¶æ¥æºæ ‡è®°
                file_header = f"\n\n## ğŸ“„ æ¥è‡ªæ–‡ä»¶: {parsed.filename}\n\n"
                merged_content.append(file_header)
                merged_content.append(parsed.content)

                parsed_count += 1

            except FileParseError as e:
                logger.warning(f"Skipping file due to parse error: {e}")
                # ç»§ç»­å¤„ç†å…¶ä»–æ–‡ä»¶,ä¸ä¸­æ–­æ•´ä¸ªæµç¨‹
                merged_content.append(f"\n\nâš ï¸ æ–‡ä»¶è§£æå¤±è´¥: {Path(file_path).name}\n")

        if parsed_count == 0:
            raise FileParseError("æ‰€æœ‰æ–‡ä»¶è§£æå‡å¤±è´¥")

        result = "".join(merged_content)
        logger.info(f"Merged content from {parsed_count}/{len(file_paths)} files")

        return result

    def extract_content_from_request(
        self,
        request: GeneratePresentationRequest,
        user_id: str | None = None,
    ) -> str:
        """
        ä»GeneratePresentationRequestä¸­æå–æ–‡ä»¶å†…å®¹

        Args:
            request: æ¼”ç¤ºæ–‡ç¨¿ç”Ÿæˆè¯·æ±‚
            user_id: ç”¨æˆ·ID(å¯é€‰)

        Returns:
            æå–çš„æ–‡ä»¶å†…å®¹(Markdownæ ¼å¼)

        Raises:
            FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
            FileParseError: æ–‡ä»¶è§£æå¤±è´¥
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ID
        if not request.files or len(request.files) == 0:
            logger.info("No files provided in request")
            return ""

        logger.info(f"Extracting content from {len(request.files)} files")

        # è·å–æ–‡ä»¶è·¯å¾„
        file_paths = []
        for file_id in request.files:
            file_path = self.file_manager.get_file_path(file_id, user_id)
            if file_path is None:
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_id}")
            file_paths.append(file_path)

        # è§£ææ‰€æœ‰æ–‡ä»¶å¹¶åˆå¹¶å†…å®¹
        content = self.parse_files(file_paths)

        logger.info(f"Extracted {len(content)} characters from files")
        return content

    def merge_content_with_topic(self, file_content: str, topic: str) -> str:
        """
        å°†æ–‡ä»¶å†…å®¹ä¸ä¸»é¢˜åˆå¹¶

        Args:
            file_content: ä»æ–‡ä»¶æå–çš„å†…å®¹
            topic: ç”¨æˆ·æä¾›çš„ä¸»é¢˜

        Returns:
            åˆå¹¶åçš„å†…å®¹
        """
        if not file_content:
            return topic

        if not topic or topic.strip() == "":
            return file_content

        # åˆå¹¶æ ¼å¼
        merged = f"""# æ¼”ç¤ºæ–‡ç¨¿ä¸»é¢˜

{topic}

---

# å‚è€ƒæ–‡æ¡£å†…å®¹

{file_content}
"""
        return merged

    async def extract_and_index_content(
        self,
        request: GeneratePresentationRequest,
        kb_manager: KnowledgeBaseManager,
        user_id: str | None = None,
    ) -> list[ParsedFileContent]:
        """
        ä»è¯·æ±‚ä¸­æå–æ–‡ä»¶å†…å®¹å¹¶ç´¢å¼•åˆ°çŸ¥è¯†åº“

        Args:
            request: æ¼”ç¤ºæ–‡ç¨¿ç”Ÿæˆè¯·æ±‚
            kb_manager: çŸ¥è¯†åº“ç®¡ç†å™¨å®ä¾‹
            user_id: ç”¨æˆ·ID(å¯é€‰)

        Returns:
            è§£æåçš„æ–‡ä»¶å†…å®¹åˆ—è¡¨

        Raises:
            FileNotFoundError: æ–‡ä»¶ä¸å­˜åœ¨
            FileParseError: æ–‡ä»¶è§£æå¤±è´¥
        """

        # æ£€æŸ¥æ˜¯å¦æœ‰æ–‡ä»¶ID
        if not request.files or len(request.files) == 0:
            logger.info("No files provided in request")
            return []

        logger.info(f"Extracting and indexing content from {len(request.files)} files")

        # è·å–æ–‡ä»¶è·¯å¾„
        file_paths = []
        for file_id in request.files:
            file_path = self.file_manager.get_file_path(file_id, user_id)
            if file_path is None:
                raise FileNotFoundError(f"æ–‡ä»¶ä¸å­˜åœ¨: {file_id}")
            file_paths.append(file_path)

        # è§£ææ‰€æœ‰æ–‡ä»¶
        parsed_files: list[ParsedFileContent] = []
        for file_path in file_paths:
            try:
                parsed = self.parse_file(file_path)
                parsed_files.append(parsed)
            except FileParseError as e:
                logger.warning(f"Skipping file due to parse error: {e}")
                continue

        if len(parsed_files) == 0:
            raise FileParseError("æ‰€æœ‰æ–‡ä»¶è§£æå‡å¤±è´¥")

        # ç´¢å¼•åˆ°çŸ¥è¯†åº“
        for parsed in parsed_files:
            metadata = {
                "file_id": parsed.file_id,
                "filename": parsed.filename,
                "word_count": parsed.word_count,
                "source": "uploaded_file",
            }

            try:
                await kb_manager.add_document(
                    content=parsed.content,
                    metadata=metadata,
                )
                logger.info(f"Indexed file to knowledge base: {parsed.filename}")
            except Exception as e:
                logger.error(f"Failed to index file {parsed.filename}: {e}")
                # ç»§ç»­ç´¢å¼•å…¶ä»–æ–‡ä»¶

        logger.info(f"Successfully indexed {len(parsed_files)} files to knowledge base")
        return parsed_files
